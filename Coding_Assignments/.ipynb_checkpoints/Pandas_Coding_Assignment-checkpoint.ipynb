{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas for Data Wrangling Assignment\n",
    "\n",
    "*Learning Objectives*: By the end of this assignment, you should be familiar with essential Pandas operations for data wrangling. Essential skills such as API familiarity, debugging, and documentation referencing will prepare you well for data science/analysis interviews and roles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "***pandas*** is a Python software library for data manipulations and analysis. It allows data imports from a variety of file formats (including CSV, JSON, and Excel) and provides several data cleaning/wrangling features. Some common features include the DataFrame object with integrated indexing, label-based slicing/indexing/subsetting of very large datasets, and integrated handling of missing data. \n",
    "\n",
    "Pandas integrates well with other Python libraries, especially Numpy for numeric processing and Matplotlib for visualizations. \n",
    "\n",
    "For this assignment, imagine you are a data analyst for a vacation rental company, BearBNB, and tasked with handling various aspects of development in San Francisco. You are supplied with datasets on listings and ratings of properties in the area. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "Running the following cell will allow us to use the most commonly used libraries that we are going to use for Data Analysis. The line `%matplotlib inline` allows us to show the graph after running a cell in which we plot a graph. That comes in really handy and is one of the powerful tools of Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.5\n"
     ]
    }
   ],
   "source": [
    "# import pandas library with pd as conventional alias\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "\n",
    "# import libraries that integrate well with pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you are familiar with Jupyter, you are strongly encouraged to become proficient with keyboard shortcuts (this will save you time in the future). To learn about keyboard shortcuts, go to **Help --> Keyboard Shortcuts** in the menu above. \n",
    "\n",
    "Here are a few that we like:\n",
    "1. `Ctrl` + `Return` : *Evaluate the current cell*\n",
    "1. `Shift` + `Return`: *Evaluate the current cell and move to the next*\n",
    "1. `ESC` : *command mode* (may need to press before using any of the commands below)\n",
    "1. `a` : *create a cell above*\n",
    "1. `b` : *create a cell below*\n",
    "1. `dd` : *delete a cell*\n",
    "1. `z` : *undo the last cell operation*\n",
    "1. `m` : *convert a cell to markdown*\n",
    "1. `y` : *convert a cell to code*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Importing and Cleaning Raw Data\n",
    "\n",
    "A **CSV file**, or **comma-separated values file** is a delimited text file that separates values with commas. \n",
    "\n",
    "A **Pandas dataframe** is a 2D labeled data structure with columns of various data types. You could think of it as a dictionary of **Series** objects, or 1D labeled array of various. \n",
    "\n",
    "<img height=200 width=200 src='series.png'>\n",
    "<img height=600 width=600 src='series_df.png'>\n",
    "\n",
    "In this assignment, you will be mainly working with Pandas dataframes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** Using *pd.read_csv*, load the ratings and listings csv files into Pandas dataframes and display the first ten lines of each dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv(\"listings.csv\")\n",
    "ratings = pd.read_csv(\"ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Display the first 10 lines of listings\n",
    "### start code ###\n",
    "\n",
    "### end code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Display the first 10 lines of ratings\n",
    "### start code ###\n",
    "\n",
    "### end code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>listings = pd.read_csv(\"listings.csv\")\n",
    "    ratings = pd.read_csv(\"ratings.csv\")\n",
    "    listings.head(10)\n",
    "    ratings.head(10)</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** What are the data types for each of the columns in listings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Display the data types of each column in each dataset\n",
    "### start code ###\n",
    "\n",
    "### end code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    \n",
    "    listings.dtypes\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** Generate descriptive statistics of all the columns (not just numerical) in listings.\n",
    "\n",
    "*Hint: Pandas already provides a function for doing this for numerical data by default.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Display descriptive statistics for each column in listings\n",
    "### start code ###\n",
    "\n",
    "### end code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    \n",
    "    listings.describe(include='all')\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** Is there a difference in the statistics that you observe for numerical versus categorical columns? Write your observations in the box below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    \n",
    "    For numeric data, we include count, mean, std, min, max as well as lower, 50 and upper percentiles.\n",
    "    For categorical data, we include count, unique, top, and freq.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** Firstly, we need to handle missing data. Implement `null_percentage`, a function that takes a dataframe object and counts the percentage of nulls in each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_percentage(df):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of null values in a dataframe.\n",
    "    \n",
    "    args:\n",
    "      df: dataframe object\n",
    "                      \n",
    "    returns:\n",
    "      percent_missing: Series object containing each column's null percentage\n",
    "      \n",
    "    \"\"\"\n",
    "    #TODO: calculate the missing percentage for each column\n",
    "    ### start code ###\n",
    "    percent_missing =...\n",
    "    ### end code ###\n",
    "    return percent_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    \n",
    "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's display the percentage of nulls for listings and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_null = null_percentage(listings)\n",
    "listings_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_null = null_percentage(ratings)\n",
    "ratings_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** We need to handle missing data before performing any analysis since null values can skew the distribution of the features. To do this, you need to find a reasonable method of replacing or removing NaN values. In the boxes below, remove the null values and provide justification as to why the method you chose is reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: handle null values in listings\n",
    "### start code ###\n",
    "\n",
    "\n",
    "### end code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Sample Solution</summary>\n",
    "    <code>\n",
    "    listings.drop(columns=['neighbourhood_group'], inplace=True)\n",
    "    listings.dropna(inplace=True)</code>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your justifications below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Sample Solution</summary>\n",
    "    \n",
    "    We drop the column that's entirely null since it won't be useful at all. \n",
    "    If we look at the percentages of nulls in reviews per month and last review, they're exactly the same. This could indicate that they're missing data at the same records, a simple scan of these rows will confirm this. These rows will not be useful since they won't contain any information in the ratings dataset (missing or no reviews of the property). Thus we drop the rows with null values in either of these columns.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** A quick scan of the <code>neighborhood</code> and <code>neighbourhood</code> columns indicate they are exactly the same. We don't want duplicates, so remove the <code>neighborhood</code> column. If you've done this in the previous step, feel free to skip this question.<br>\n",
    "*Hint: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html might be useful.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Remove the neighborhood column in the listings dataframe\n",
    "### start code ###\n",
    "\n",
    "\n",
    "### end code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>listings.drop(columns=[\"neighborhood\"],inplace=True)</code>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identifying Outliers\n",
    "Determining outliers is one of the biggest challenges in cleaning data, but the performance of machine learning algorithms will be heavily affected if they aren't removed. The following section will focus on introducing different methods of identifying these data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** As you are probably familiar with, the interquartile range can be used to measure statistical dispersion. Calculate the IQR of each of the numerical columns in `listings`.<br>\n",
    "*Hint: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html might be useful.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellipsis\n"
     ]
    }
   ],
   "source": [
    "#TODO: Determine the IQR for each column in listings\n",
    "### start code ###\n",
    "Q1 =...\n",
    "Q3 =...\n",
    "IQR =...\n",
    "print(IQR)\n",
    "\n",
    "### end code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>Q1 = listings.quantile(0.25)\n",
    "Q3 = listings.quantile(0.75) \n",
    "IQR = Q3 - Q1 \n",
    "print(IQR)  </code>\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** Similarly, implement `remove_outliers_IQR` to remove the rows that are outside `(Q1 - 1.5*IQR, Q3 + 1.5*IQR)` for columns `minimum_nights`, `number_of_reviews`, `reviews_per_month`, and `calculated_host_listings_count`. For this part, you are required to use `loc` to remove the outliers. Refer to https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html for more information on `loc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>958</td>\n",
       "      <td>Bright, Modern Garden Unit - 1BR/1BTH</td>\n",
       "      <td>1169</td>\n",
       "      <td>Holly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Addition</td>\n",
       "      <td>37.76931</td>\n",
       "      <td>-122.43386</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5858</td>\n",
       "      <td>Creative Sanctuary</td>\n",
       "      <td>8904</td>\n",
       "      <td>Philip And Tania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bernal Heights</td>\n",
       "      <td>37.74511</td>\n",
       "      <td>-122.42102</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>235</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7918</td>\n",
       "      <td>A Friendly Room - UCSF/USF - San Francisco</td>\n",
       "      <td>21994</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haight Ashbury</td>\n",
       "      <td>37.76555</td>\n",
       "      <td>-122.45213</td>\n",
       "      <td>Private room</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8014</td>\n",
       "      <td>Newly Remodeled room in big house WIFI market</td>\n",
       "      <td>22402</td>\n",
       "      <td>Jia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outer Mission</td>\n",
       "      <td>37.73075</td>\n",
       "      <td>-122.44841</td>\n",
       "      <td>Private room</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8142</td>\n",
       "      <td>Friendly Room Apt. Style -UCSF/USF - San Franc...</td>\n",
       "      <td>21994</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haight Ashbury</td>\n",
       "      <td>37.76555</td>\n",
       "      <td>-122.45213</td>\n",
       "      <td>Private room</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8339</td>\n",
       "      <td>Historic Alamo Square Victorian</td>\n",
       "      <td>24215</td>\n",
       "      <td>Rosy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Addition</td>\n",
       "      <td>37.77525</td>\n",
       "      <td>-122.43637</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>743</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8739</td>\n",
       "      <td>Mission Sunshine, with Private Bath</td>\n",
       "      <td>7149</td>\n",
       "      <td>Ivan &amp; Wendy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mission</td>\n",
       "      <td>37.76030</td>\n",
       "      <td>-122.42197</td>\n",
       "      <td>Private room</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>736</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>5.41</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10251</td>\n",
       "      <td>Victorian Suite in Inner Mission</td>\n",
       "      <td>35199</td>\n",
       "      <td>Roman &amp; Sarah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mission</td>\n",
       "      <td>37.75831</td>\n",
       "      <td>-122.41386</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>337</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10578</td>\n",
       "      <td>Classic Nob Hill Studio - Roof Deck</td>\n",
       "      <td>37049</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nob Hill</td>\n",
       "      <td>37.79143</td>\n",
       "      <td>-122.41544</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>2015-05-17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10820</td>\n",
       "      <td>Haight Buena Vista Park Garden 3BR</td>\n",
       "      <td>38836</td>\n",
       "      <td>Bernat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haight Ashbury</td>\n",
       "      <td>37.77187</td>\n",
       "      <td>-122.43859</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>170</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>38</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               name  host_id  \\\n",
       "0    958              Bright, Modern Garden Unit - 1BR/1BTH     1169   \n",
       "1   5858                                 Creative Sanctuary     8904   \n",
       "2   7918         A Friendly Room - UCSF/USF - San Francisco    21994   \n",
       "3   8014      Newly Remodeled room in big house WIFI market    22402   \n",
       "4   8142  Friendly Room Apt. Style -UCSF/USF - San Franc...    21994   \n",
       "5   8339                    Historic Alamo Square Victorian    24215   \n",
       "6   8739                Mission Sunshine, with Private Bath     7149   \n",
       "7  10251                   Victorian Suite in Inner Mission    35199   \n",
       "8  10578                Classic Nob Hill Studio - Roof Deck    37049   \n",
       "9  10820                 Haight Buena Vista Park Garden 3BR    38836   \n",
       "\n",
       "          host_name  neighbourhood_group     neighbourhood  latitude  \\\n",
       "0             Holly                  NaN  Western Addition  37.76931   \n",
       "1  Philip And Tania                  NaN    Bernal Heights  37.74511   \n",
       "2             Aaron                  NaN    Haight Ashbury  37.76555   \n",
       "3               Jia                  NaN     Outer Mission  37.73075   \n",
       "4             Aaron                  NaN    Haight Ashbury  37.76555   \n",
       "5              Rosy                  NaN  Western Addition  37.77525   \n",
       "6      Ivan & Wendy                  NaN           Mission  37.76030   \n",
       "7     Roman & Sarah                  NaN           Mission  37.75831   \n",
       "8            Andrew                  NaN          Nob Hill  37.79143   \n",
       "9            Bernat                  NaN    Haight Ashbury  37.77187   \n",
       "\n",
       "   longitude        room_type  price  minimum_nights  number_of_reviews  \\\n",
       "0 -122.43386  Entire home/apt    131               2                262   \n",
       "1 -122.42102  Entire home/apt    235              30                111   \n",
       "2 -122.45213     Private room     56              32                 19   \n",
       "3 -122.44841     Private room     45               5                 85   \n",
       "4 -122.45213     Private room     56              32                  8   \n",
       "5 -122.43637  Entire home/apt    743               5                 28   \n",
       "6 -122.42197     Private room    169               1                736   \n",
       "7 -122.41386  Entire home/apt    200              30                337   \n",
       "8 -122.41544  Entire home/apt    120              30                 18   \n",
       "9 -122.43859  Entire home/apt    170              30                 37   \n",
       "\n",
       "  last_review  reviews_per_month  calculated_host_listings_count  \\\n",
       "0  2020-09-16               1.92                               1   \n",
       "1  2017-08-06               0.80                               1   \n",
       "2  2020-03-06               0.14                               9   \n",
       "3  2018-10-01               0.85                               2   \n",
       "4  2018-09-12               0.11                               9   \n",
       "5  2019-06-28               0.21                               2   \n",
       "6  2020-03-16               5.41                               2   \n",
       "7  2019-05-27               2.50                               1   \n",
       "8  2015-05-17               0.17                               1   \n",
       "9  2018-12-01               0.28                              38   \n",
       "\n",
       "   availability_365  \n",
       "0               206  \n",
       "1               365  \n",
       "2               365  \n",
       "3                45  \n",
       "4               365  \n",
       "5                 0  \n",
       "6               179  \n",
       "7               365  \n",
       "8               364  \n",
       "9                73  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_outliers_IQR(df, cols):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of null values in a dataframe.\n",
    "    \n",
    "    args:\n",
    "      df: dataframe object\n",
    "      cols: list of numerical columns in df that should be filtered\n",
    "      \n",
    "    returns:\n",
    "      removed: df with outliers removed \n",
    "      \n",
    "    \"\"\"\n",
    "    #TODO: remove outliers in df using loc\n",
    "    removed = df\n",
    "    ### start code ###\n",
    "\n",
    "    ### end code ###\n",
    "    return removed\n",
    "\n",
    "numerical_columns = ['price','minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "                     'calculated_host_listings_count']\n",
    "listings = remove_outliers_IQR(listings, numerical_columns)\n",
    "listings.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>for name in numerical_columns:\n",
    "        Q1 = df[name].quantile(0.25)\n",
    "        Q3 = df[name].quantile(0.75)\n",
    "        IQR = Q3-Q1\n",
    "        lower = Q1 - 1.5*IQR\n",
    "        upper = Q3 + 1.5*IQR\n",
    "        removed = removed.loc[(removed[name] > lower) & (removed[name] < upper)] </code>\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data manipulation\n",
    "**Question 4.1** Perhaps we want to segment the dataset based on neighborhood. Using `groupby()`, create a dataframe called `listings_neighborhoods` that's indexed by each unique neighborhood and have the numerical columns aggregated by their means. Reference to `groupby`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_neighborhoods =...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>listings_neighborhoods = listings.groupby([\"neighbourhood\"]).agg(np.mean) </code>\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2** Using `transform()`, try standardizing each column in the groupby dataframe we just created. Reference to `transform`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods_standardized =..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>neighborhoods_standardized = listings_neighborhoods.transform(lambda x: (x - x.mean()) / x.std())</code>\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3** Using any method, identify the highest price of each room type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_rooms =..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>listings_rooms = listings.loc[listings.groupby('room_type')['price'].idxmax()]</code>\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4** What are the similarities and differences between **aggregating, filtering, and transforming** grouped objects?<br>\n",
    "*Hint: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#aggregation might be useful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    Aggregating is a part of the split, apply, and combine process. First the data is split into groups, then one or more functions are applied to each group. The result is aggregated by the agg() function and returned as a series that can be converted to a datagrame via reset_index.<br>\n",
    "    <br>\n",
    "    Transforming utilizes an extra step between applying and combining called broadcasting. This is where the results of sub dataframes (groups) are broadcasted to the original, full dataframe. You can think of this as a left merge of the results with the original dataset.<br>\n",
    "    <br>\n",
    "    Filtering takes one step further and filters between applying and broadcasting. Now our process looks like: split->apply->filter->broadcast->combine. As the name suggests, the results of splitting and applying are filtered to meet a certain criteria and those rows meeting the criteria are broadcasted to the original table.\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5** You've probably noticed that one of the columns in our `listings` dataframe appears to be a date column. When we ran `listings.dtypes` earlier, there wasn't any `datetime` type. This is because of `read_csv()` and the fact that csv files only contain integers, strings, and floats. At load time, is there any way of converting a date column to datetime? Refer to https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html for documentation on `read_csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    Yes, Pandas provides a keyword argument for read_csv(), parse_dates for this functionality. Creating a custom parser might be necessary.\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6** Check if any of the columns are in a datetime format already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "#TODO: Check for the existence of datetime type columns in listings\n",
    "### start code ###\n",
    "\n",
    "\n",
    "### end code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>listings[[column for column in listings.columns if is_datetime(listings[column])]]</code>\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.7** Now convert the `last_review` column into a datetime format. Specify the formatting of the datetime column manually instead of letting Pandas infer it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Convert last_review column to datetime\n",
    "### start code ###\n",
    "\n",
    "\n",
    "### end code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>listings['last_review'] = pd.to_datetime(listings['last_review'], format = '%Y-%m-%d')</code>\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pivoting and Joins\n",
    "It's important to understand different ways you can restructure your dataframe. This includes reshaping the dataframe based on columns or joining with a new dataframe.<br>\n",
    "**Question 5.1** Using <code>pivot_table</code>, create a dataframe containing the average price, reviews per month, and availability for each room type per each unique neighborhood. Documentation on `pivot_table`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Use pivot_table to create a dataframe containing the average price,\n",
    "#reviews per month, and availability for each room type per each unique neighborhood.\n",
    "### start code ###\n",
    "\n",
    "\n",
    "### end code ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>pd.pivot_table(listings, values = ['price', 'reviews_per_month', 'availability_365'], index = ['neighbourhood', 'room_type'],aggfunc= np.mean)</code>\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.2** What's the difference between `pivot` and `pivot_table`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    Pivot provides general functionality for pivoting with general data types while pivot_table allows us to pivot with numerical aggregation.\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.3** Recall that our `ratings` dataframe contains recorded ratings for listing ids. In order to join this dataframe with `listings` we need a shared column. Naturally, we should choose the listing id since this is a unique identifier for each property. Using the tools from this homework, transform `ratings` to contain unique property ids and their average ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>ratings = pd.pivot_table(ratings, values = ['rating'], index = ['listing_id'], aggfunc = np.mean)</code>\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.4** Now join `listings` with `ratings`. Call the ratings column, `average_rating`. As a sanity check, make sure there are no null values in the entire joined dataframe. Refer to https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_full =...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>listings_full = listings.join(ratings, on='id')</code><br>\n",
    "    <code>listings_full.rename(columns = {'rating':'average_rating'}, inplace=True)</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. One-hot encoding\n",
    "To prepare our data to be input into a model, we should one-hot encode the categorical variables that we're using. Pandas provides `get_dummies` for this functionality. See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html for more information.<br>\n",
    "**Question 6.1** One-hot encode `room_type` in `listings_full`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: One-hot encode `room_type` in `listings_full`.\n",
    "### start code ###\n",
    "\n",
    "### end code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <code>pd.get_dummies(listings_full, columns=['room_type'])</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Putting it all together\n",
    "In this last section, you'll have an opportunity to use the Pandas tools that you've learned in this assignment as well as utilize other tools you may have learned from the documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7** Now that we've compiled a single, clean dataset on vacation rental properties, BearBNB wants to hear your recommendations. In particular, provide a consulting strategy on how they should invest their resources. This question is meant to be open ended, but provide evidence and visualizations to back your claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### start code ###\n",
    "\n",
    "\n",
    "### end code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    Any attempt that contains a valid segmentation of the dataset along with descriptive statistics of the categories is accepted. This can include neighborhoods, room types, reviews, etc. \n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
